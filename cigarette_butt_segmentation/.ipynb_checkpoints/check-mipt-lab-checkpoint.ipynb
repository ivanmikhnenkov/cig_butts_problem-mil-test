{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for opencv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2567ee5cfc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# os.chdir(\"/kaggle/input/cig-butts/cig_butts_data/\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencode_rle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_rle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_img_with_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mpti_lab_test/cv-general-task/cigarette_butt_segmentation/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mencode_rle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_rle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_img_with_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mpti_lab_test/cv-general-task/cigarette_butt_segmentation/lib/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "# import cv2\n",
    "import collections\n",
    "import time \n",
    "import tqdm\n",
    "from PIL import Image\n",
    "# from functools import partial\n",
    "# train_on_gpu = True\n",
    "\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "# import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "# from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "# import albumentations as A\n",
    "\n",
    "\n",
    "# from catalyst.data import Augmentor\n",
    "# from catalyst.dl import utils\n",
    "# # from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
    "# from catalyst.dl.runner import SupervisedRunner\n",
    "# from catalyst.contrib.models.cv.segmentation import Unet\n",
    "# from catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback\n",
    "\n",
    "# import segmentation_models_pytorch as smp\n",
    "\n",
    "# os.chdir(\"/kaggle/input/cig-butts/cig_butts_data/\")\n",
    "from lib.metrics import get_dice\n",
    "from lib.utils import encode_rle, decode_rle, get_mask\n",
    "from lib.show import show_img_with_mask\n",
    "from lib.html import get_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GettingStarted.ipynb',\n",
       " '.DS_Store',\n",
       " 'check-mipt-lab.ipynb',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = \"cig_butts/cig_butts/train/images/\"\n",
    "train_annotations_path = \"cig_butts/cig_butts/train/coco_annotations.json\"\n",
    "\n",
    "val_images_path = \"cig_butts/cig_butts/val/images/\"\n",
    "val_annotations_path = \"cig_butts/cig_butts/val/coco_annotations.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание было выполнено на kaggle.com из-за наличия у них GPU \n",
    "# Все результаты экспериментов сохраняются внутри папки указанной внизу\n",
    "# Для повторения эксперимента в другой среде измените путь RES_DIR\n",
    "RES_DIR = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_annotations_path) as ta:\n",
    "    train_annotations = json.load(ta)\n",
    "    \n",
    "with open(val_annotations_path) as va:\n",
    "    val_annotations = json.load(va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"Отобразить изображение в один ряд с ключами как названиями над ними\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CigDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс созданный специально для обработки набора данных cig butts\n",
    "    \"\"\"\n",
    "    def __init__(self, images_path, annotations, augmentations = None, image_preprocessing = None):\n",
    "        self.images_path = images_path\n",
    "        self.image_names = os.listdir(images_path)\n",
    "        self.annotations = annotations\n",
    "        self.augmentations = augmentations\n",
    "        self.image_preprocessing = image_preprocessing\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images_path + self.image_names[idx]\n",
    "        image = np.array(Image.open(image_path))[:, :, 0:3]\n",
    "\n",
    "        mask_id = int(image_path[-12:-4])\n",
    "        mask = get_mask(mask_id, self.annotations)\n",
    "    \n",
    "        \n",
    "        # augmentations application\n",
    "        if self.augmentations != None:\n",
    "            sample = self.augmentations(image = image, mask = mask)\n",
    "            image, mask = sample[\"image\"], sample[\"mask\"]\n",
    "            \n",
    "        # preprocessing application\n",
    "        if self.image_preprocessing != None:\n",
    "            image = self.image_preprocessing(image)\n",
    "        \n",
    "        # mask to binary one-hot torch format tensor\n",
    "        mask = np.stack([mask / 255], axis = -1)\n",
    "        mask = torch.from_numpy(mask).permute(2, 0, 1).float()\n",
    "        \n",
    "        return (image, mask)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аугментация и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изображения нашего набора данных не чувствительны к ориентации, \n",
    "# поэтому A.Flip испрользуется как базовая аугментация с вер-ью 0.75\n",
    "def get_augmentations():\n",
    "    augmentation_transform = A.Compose([\n",
    "        A.Flip(p = 0.75)\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    return augmentation_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация моделей segmentation models pytorch на данных imagenet (https://pytorch.org/docs/stable/torchvision/models.html)\n",
    "NORM_PARAMS = {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "\n",
    "def get_preprocessing(norm_params):\n",
    "\n",
    "    preprocessing_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=norm_params[\"mean\"],\n",
    "                             std=norm_params[\"std\"])\n",
    "    ])\n",
    "    \n",
    "    return preprocessing_transform\n",
    "\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, norm_params):\n",
    "        self.mean = norm_params[\"mean\"]\n",
    "        self.std = norm_params[\"std\"]\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm = UnNormalize(NORM_PARAMS)\n",
    "to_pil = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmentation = get_augmentations()\n",
    "preprocessing = get_preprocessing(NORM_PARAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели и датасетов для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = \"efficientnet-b4\"\n",
    "model = smp.DeepLabV3Plus(encoder_name = ENCODER, \n",
    "                 encoder_weights = \"imagenet\", \n",
    "                 classes = 1, \n",
    "                 activation = \"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CigDataset(images_path = train_images_path, \n",
    "                           annotations = train_annotations, \n",
    "                           augmentations = train_augmentation, \n",
    "                           image_preprocessing = preprocessing)\n",
    "val_dataset = CigDataset(images_path = val_images_path, \n",
    "                           annotations = val_annotations, \n",
    "                           augmentations = None, \n",
    "                           image_preprocessing = preprocessing)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, drop_last = False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False, drop_last = False)\n",
    "\n",
    "loaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"valid\": val_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели с использованием Catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "logdir = RES_DIR + \"logs\"\n",
    "\n",
    "# model, criterion, optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.decoder.parameters(), 'lr': 1e-2}, \n",
    "    {'params': model.encoder.parameters(), 'lr': 1e-3},  \n",
    "])\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.15, patience=1)\n",
    "criterion = smp.utils.losses.DiceLoss()\n",
    "runner = SupervisedRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    callbacks=[DiceCallback(), EarlyStoppingCallback(patience=5, min_delta=0.001)],\n",
    "    logdir=logdir,\n",
    "    num_epochs=num_epochs,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение модели в дерикторию с результами\n",
    "torch.save(model, RES_DIR + \"deeplabv3plus_b4_20ep.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображение процесса обучения: динамика loss, динамика learning rate\n",
    "utils.plot_metrics(\n",
    "    logdir=logdir, \n",
    "    metrics=[\"loss\", 'lr', '_base/lr']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры предсказаний на валидационном наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        image, mask = val_dataset[i]\n",
    "        prediction = model(image.unsqueeze(0).to(DEVICE))\n",
    "        pred_mask = prediction.squeeze().round().to(\"cpu\").numpy()\n",
    "        mask_np = mask.squeeze().numpy()\n",
    "        visualize(image = to_pil(unnorm(image)), true_mask = mask_np, predicted_mask = pred_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка dice coefficient модели на валидационных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dice_coefficient(model, dataset):\n",
    "    \"\"\"\n",
    "    Возвращает среднее значение dice coefficient для предсказаний данной model для всех элементов данных из dataset.\n",
    "    Использовать в контексте данного ноутбука из-за зависимостей.\n",
    "    \n",
    "    model: segmentation model in torch\n",
    "    dataset: torch.utils.data.Dataset\n",
    "    return: float number representing mean dice coefficient\n",
    "    \"\"\"\n",
    "    DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model.to(DEVICE)\n",
    "    dice_coef = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(val_dataset)):\n",
    "            image, mask = val_dataset[i]\n",
    "            prediction = model(image.unsqueeze(0).to(DEVICE))\n",
    "            pred_mask = prediction.squeeze().round().to(\"cpu\").numpy()\n",
    "            mask_np = mask.squeeze().numpy()\n",
    "            dice_coef += get_dice(mask_np, pred_mask)\n",
    "\n",
    "        return dice_coef / len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_dice_unet_b4_20ep = estimate_dice_coefficient(model, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Средний dice коэффициент модели UNet c encoder efficientnetb4 на валидационном наборе данных после 20 эпох обучения:\", round(average_dice_unet_b4_20ep, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## История результатов для моделей и аугментаций\n",
    "### UNet + EfficientNetB4\n",
    "    Средний dice коэффициент модели UNet c encoder efficientnetb4 на валидационном наборе данных после 10 эпох обучения: 0.963\n",
    "    Аугментации: [A.Flip(p = 0.75)]\n",
    "    Название файла модели: unet_b4_10ep.pth\n",
    "    Комментарий: базовая модель на небольшом количестве эпох с минимальной аугментацией показала неплохой результат.  \n",
    "    Efficientnet b4 был использован т.к. это новый и совершенный encoder, превосходящий по качеству классификации более \n",
    "    традиционные encoder, например Resnet 50. \n",
    "    Также конфигурация b4 является достаточно небольшой по количеству параметров, в тоже время эффективно улучшает \n",
    "    результат предсказания по сравнению c b3. Такой разницы между b4 и b5 на задаче классификации на данных imagenet \n",
    "    не наблюдается [https://arxiv.org/pdf/1905.11946.pdf].\n",
    "    \n",
    "    Эта же модель была дообучена еще на 10 эпохах.\n",
    "    Средний dice коэффициент модели UNet c encoder efficientnetb4 на валидационном наборе данных после 20 эпох\n",
    "    обучения: 0.964\n",
    "    Метрики в конце обучения:\n",
    "    10/10 * Epoch 10 (train): loss=0.0326\n",
    "    10/10 * Epoch 10 (valid): loss=0.0292 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(RES_DIR + \"unet_b4_20ep.pth\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание таблицы с закодированными масками сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_names = os.listdir(\"cig_butts/cig_butts/val/images\")\n",
    "# Сортировка в соответствии с именем и image id для корректного заполнения таблицы масок\n",
    "val_names.sort()\n",
    "masks_as_rle = []\n",
    "\n",
    "preprocessing = get_preprocessing(NORM_PARAMS)\n",
    "\n",
    "model.eval()\n",
    "for val_img_id in range(len(val_names)):\n",
    "    image_path = val_images_path + val_names[val_img_id]\n",
    "    image = np.array(Image.open(image_path))[:, :, 0:3]\n",
    "    image = preprocessing(image)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        prediction = model(image.unsqueeze(0).to(DEVICE))\n",
    "        pred_mask = prediction.squeeze().round().to(\"cpu\").numpy()\n",
    "        masks_as_rle.append(encode_rle(pred_mask))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оформление полученных значений в dataframe и сохранение как таблицы .csv\n",
    "masks_df = pd.DataFrame(masks_as_rle, columns = [\"rle_mask\"])\n",
    "masks_df.index.name = \"img_id\"\n",
    "masks_df.to_csv(RES_DIR + \"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание масок для тестовой выборке и оформление в html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_path = \"cig_butts/cig_butts/real_test/\"\n",
    "real_images_names = os.listdir(real_images_path)\n",
    "real_images_names.sort()\n",
    "real_images_paths = [real_images_path + name for name in real_images_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "dice_coef = 0\n",
    "preprocessing = get_preprocessing(NORM_PARAMS)\n",
    "predicted_masks = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image_path in real_images_paths:\n",
    "        image = np.array(Image.open(image_path))[:, :, 0:3]\n",
    "        image = preprocessing(image)\n",
    "        prediction = model(image.unsqueeze(0).to(DEVICE))\n",
    "        pred_mask = prediction.squeeze().round().to(\"cpu\").numpy()\n",
    "        predicted_masks.append(pred_mask.astype(\"uint8\"))\n",
    "        show_img_with_mask(to_pil(unnorm(image)), pred_mask)\n",
    "\n",
    "os.mkdir(RES_DIR + \"html_dir1\")\n",
    "get_html(real_images_paths, predicted_masks, RES_DIR + \"html_dir1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
